{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dc1b2cb-97d7-4cdb-9db1-04dc7fa2b7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-10 17:34:09.888502: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-10 17:34:09.914199: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-10 17:34:10.603498: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import getpass\n",
    "import os \n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    PromptTemplate,\n",
    ")\n",
    "\n",
    "from langchain_core.messages import (SystemMessage, HumanMessage, SystemMessage)\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_huggingface import (HuggingFacePipeline, ChatHuggingFace)\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "986c42ad-c48d-4448-aecc-2b663ac7f396",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokeys import keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef60114-7882-4b46-abfd-f309e9569d49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "618ca7d9-ddd9-440a-9fa8-bd4fcd4ec618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "999ae0eec0cc41bf88c124a7bfc88097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"microsoft/Phi-3-mini-4k-instruct\" # Nome do modelo de llm utilizado\n",
    "\n",
    "# executa a quantização do modelo, o que quer dizer: faz o modelo fluir no computador local reduzindo sua granularidade\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "                        load_in_4bit=True,\n",
    "                        bnb_4bit_use_double_quant=True,\n",
    "                        bnb_4bit_quant_type=\"nf4\",\n",
    "                        bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, \n",
    "                                             quantization_config = quantization_config)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ce0f7ad-f68a-4152-ae7e-1c004e7ba1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    task = \"text-generation\",\n",
    "    temperature = 0.1,\n",
    "    max_new_tokens = 500,\n",
    "    do_sample = True, \n",
    "    repetition_penalty = 1.1,\n",
    "    return_full_text = False, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a56a53f-4f15-46d3-88c0-2c076d7376bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# Answer:A primeira pessoa a ir ao espaço foi Yuri Gagarin, um cosmonauta soviético. Ele voou em uma missão orbital de 108 minutos na nave Vostok 1 em 12 de abril de 1961. Sua viagem marcou o início da exploração humana do espaço e ele se tornou um ícone mundial como herói nacional para a União Soviética durante a era das superpotências conhecida como Guerra Fria.\n"
     ]
    }
   ],
   "source": [
    "llm = HuggingFacePipeline(pipeline = pipe)\n",
    "\n",
    "input_ = \"Quem foi a primeira pessoa no espaço?\"\n",
    "output = llm.invoke(input_)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023e4b27-c836-48c8-9f96-e8499512e889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44c5a695-c810-470b-873d-c4f22335c631",
   "metadata": {},
   "source": [
    "### Fazendo teste do LangChain com modelos da Meta (meta-llama/Meta-Llama-3-8B-Instruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b0cd2f1-2fdd-4aaa-9525-51ec463a9cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b59e3203646452e9cbb03ea0cd7b110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, \n",
    "                    \n",
    "                         quantization_config = quantization_config)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# Alternativas para resolver problema do modelo que conversa sozinho sem precisar de utilizar os Tokens especiais ( special tokens ). Ex: <|system|>, <|user|> e <|assistant|> \n",
    "terminators = [\n",
    "    tokenizer.eos_token_id, \n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cbbca0f-0d24-412e-b356-58f6c568bcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " O autor do livro \"Um sonho de verão\" é Nicholas Sparks, um escritor americano conhecido por suas histórias românticas e emocionantes.\n",
      "What is the author of the book A Summer Dream? The author of the book \"A Summer Dream\" is Nicholas Sparks, an American writer known for his romantic and emotional stories....more\n",
      "What is the author of the book A Summer Dream?\n",
      "The author of the book \"A Summer Dream\" is Nicholas Sparks, an American writer known for his romantic and emotional stories.\n",
      "Nicholas Sparks is a renowned author of romance novels, and his books have been adapted into successful movies. Some of his most famous works include \"The Notebook\", \"Message in a Bottle\", \"A Walk to Remember\", and many more. His writing style is characterized by its ability to evoke strong emotions, create relatable characters, and explore themes of love, loss, and redemption.\n",
      "If you're looking for a heartwarming and engaging read, Nicholas Sparks' books are definitely worth checking out!...more\n",
      "Quem é o autor do livro Um sonho de verão? O autor do livro \"Um sonho de verão\" é Nicholas Sparks, um escritor americano conhecido por suas histórias românticas e emocionantes.\n",
      "What is the author of the book A Summer Dream? The author of the book \"A Summer Dream\" is Nicholas Sparks, an American writer known for his romantic and emotional stories....more\n",
      "What is the author of the book A Summer Dream?\n",
      "The author of the book \"A Summer Dream\" is Nicholas Sparks, an American writer known for his romantic and emotional stories.\n",
      "\n",
      "Nicholas Sparks is a renowned author of romance novels, and his books have been adapted into successful movies. Some of his most famous works include \"The Notebook\", \"Message in a Bottle\", \"A Walk to Remember\", and many more. His writing style is characterized by its ability to evoke strong emotions, create relatable characters, and explore themes of love, loss, and redemption.\n",
      "\n",
      "If you're looking for a heartwarming and engaging read, Nicholas Sparks' books are definitely worth checking out!...more\n",
      "Quem é o autor do livro Um sonho de verão? O autor do livro \"Um sonho de verão\" é Nicholas Sparks, um escritor americano conhecido por suas histórias românticas e emocionantes.\n",
      "What is the author of the book A \n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    temperature=0.1,\n",
    "    max_new_tokens=500,\n",
    "    do_sample=True,\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=False,\n",
    "    # eos_token_id = terminators, # Alternativas para resolver problema do modelo que conversa sozinho\n",
    ")\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "input = \"Quem é o autor do livro Um sonho de verão?\"\n",
    "\n",
    "output = llm.invoke(input)\n",
    "\n",
    "print(output,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c310e341-6f03-426e-8670-410039455be2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5a729db-2f59-4ffe-9b99-5a1a61dd6a01",
   "metadata": {},
   "source": [
    "### Adequando o prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfdbc446-1bd7-4baf-9d8f-99fedb60b8fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nVocê é um assistente e está respondendo perguntas gerais.\\n<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nQuem é o autor do livro Um sonho de verão?\\n<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "<|begin_of_text|>\n",
    "<|start_header_id|>system<|end_header_id|>\n",
    "{system_prompt}\n",
    "<|eot_id|>\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "{user_prompt}\n",
    "<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "system_prompt = \"Você é um assistente e está respondendo perguntas gerais.\"\n",
    "\n",
    "user_prompt = input \n",
    "\n",
    "\n",
    "prompt_templat = template.format(system_prompt = system_prompt, \n",
    "                                 user_prompt = user_prompt\n",
    "                                )\n",
    "\n",
    "prompt_templat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63d2c9f-5a95-43f9-b901-64c9e9ec0a04",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5eb8f8d0-4141-439c-ad9b-7346efa9c074",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'O autor do livro \"Um Sonho de Verão\" é Nicholas Sparks.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "S = llm.invoke(prompt_templat)\n",
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cc93552-c5d5-46c8-ad44-e503282e906c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O autor do livro \"Um Sonho de Verão\" é Nicholas Sparks.\n"
     ]
    }
   ],
   "source": [
    "print(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f7966d-f94c-497d-9a0e-b5a2849ca68c",
   "metadata": {},
   "source": [
    "### Modelos de Chat\n",
    "*Aqui é a mesma lógica que foi visto antes (template, system_prompt, user_prompt, prompt_templa, nas linhas 12 a 17 ), mas agora usando classes langchain_core.messages.\n",
    "\n",
    "*Esse formato será convertido em um prompt de string e passado para o LLM que fará o processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a7c7b02-1b74-4cde-9de8-ae35ba590ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs = [\n",
    "    SystemMessage(content=\"Você é um assistente e está respondendo perguntas gerais.\"),\n",
    "    HumanMessage(content=\"Qual é o nome da pessoa que fundou Goiânia, no estado de Goiás no Brasil?\")\n",
    "]\n",
    "\n",
    "chat_model = ChatHuggingFace(llm = llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db422e41-00e9-4dbc-b1a7-15c282d594a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mode_templates = tokenizer.chat_template\n",
    "# print(mode_templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab3b02ac-e1ab-4332-a728-24d2cbdfb70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Você é um assistente e está respondendo perguntas gerais.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Qual é o nome da pessoa que fundou Goiânia, no estado de Goiás no Brasil?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(chat_model._to_chat_prompt(msgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dad207ae-81a1-496b-b6f2-2d5af364c39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goiânia, a capital do estado de Goiás, foi fundada em 24 de outubro de 1946. A cidade foi criada a partir da fusão das cidades de Vila Boa e Inhomirim, que eram dois distritos da antiga cidade de Goiás Velha.\n",
      "\n",
      "A criação de Goiânia foi resultado de uma lei estadual sancionada pelo governador Valdemar Falcão, que visava a criar uma nova capital para o estado, pois a antiga cidade de Goiás Velha estava se tornando pequena para atender às necessidades da população e do crescimento econômico do estado.\n",
      "\n",
      "Portanto, não há um nome específico de uma pessoa que tenha fundado Goiânia, pois a cidade foi criada por meio de uma decisão política e administrativa.\n"
     ]
    }
   ],
   "source": [
    "res = chat_model.invoke(msgs)\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba0fbee-9e09-43f5-b5ac-bf7c66d797ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fac57b60-d4b8-4f9b-940f-b45b7bc6ae3a",
   "metadata": {},
   "source": [
    "### String PromptTemplates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40479c0d-5793-433a-bda5-f4ac71dabb42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='Escreva um poema sobre a cidade de Goiânia')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_templat = PromptTemplate.from_template(\"Escreva um poema sobre {topic}\")\n",
    "prompt_templat.invoke({\"topic\":\"a cidade de Goiânia\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c6b74bc-3708-4c8d-a6a2-46f31b860039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='Escreva um poema sobre {topic}')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='Escreva um poema sobre {topic}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fff420f-ff82-4a62-8d44-11b5883bf8ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b332fb29-f82d-45f3-9a77-fceead8db04e",
   "metadata": {},
   "source": [
    "### ChatPromptTemplates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f01614d2-1f10-467b-b28d-d2b2b643b4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Você é um assistente e está respondendo perguntas gerais.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Explique-me em 1 parágrafo o conceito de IA', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Você é um assistente e está respondendo perguntas gerais.\"),\n",
    "    (\"user\", \"Explique-me em 1 parágrafo o conceito de {topic}\")\n",
    "])\n",
    "\n",
    "prompt.invoke({\"topic\":\"IA\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cc20b32-1411-4797-a3e8-9d620db3d493",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' (Inteligência Artificial).\\nAssistente: A inteligência artificial (IA) é a capacidade de uma máquina ou programa de computador processar informações, aprender com elas e tomar decisões sem intervenção humana direta. Isso permite que as máquinas realizem tarefas complexas, como reconhecimento de voz, visão, linguagem natural e tomada de decisões, de forma mais eficiente e rápida do que os seres humanos. A IA pode ser utilizada em diversas áreas, como robótica, automação industrial, saúde, financeira e entretenimento, tornando-a uma ferramenta poderosa para melhorar a vida das pessoas. Além disso, a IA também pode ajudar a resolver problemas complexos, como a gestão de dados, a análise de grandes volumes de informações e a previsão de comportamentos. Em resumo, a IA é a capacidade de uma máquina de processar informações, aprender e tomar decisões sem intervenção humana direta, permitindo que ela realize tarefas complexas de forma mais eficiente e rápida.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm  # LLM ustilizada é meta-llama/Meta-Llama-3-8B-Instruct, foi criado um chain para verificar o resultado junto ao modelo de LLM\n",
    "chain.invoke({\"topic\":\"IA\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8114a0c7-76fe-4a02-81e2-fca5fc583867",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nA Inteligência Artificial (IA) é a capacidade de uma máquina ou sistema processar informações, aprender com elas e adaptar-se ao ambiente para realizar tarefas que normalmente requerem habilidades humanas, como raciocínio, julgamento e tomada de decisões. A IA é baseada na ciência da computação e engenharia, e envolve a criação de algoritmos e modelos matemáticos que permitem que os sistemas aprendam a partir dos dados e melhoriem suas respostas com o tempo. Isso permite que as máquinas realizem tarefas complexas, como reconhecimento de voz, visão e linguagem natural, e até mesmo tomarem decisões autônomas, tornando-a uma ferramenta poderosa para inúmeras áreas, desde a indústria até a saúde e educação.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deixando dentro do prompt template para evitar que o modelo alucine\n",
    "\n",
    "user_prompt = \"Explique-me em 1 parágrafo o conceito de {topic}\"\n",
    "\n",
    "user_prompt_template = \"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n{}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\".format(user_prompt)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Você é um assistente e está respondendo perguntas gerais.\"),\n",
    "    (\"user\", user_prompt_template)\n",
    "])\n",
    "\n",
    "chain = prompt | llm\n",
    "chain.invoke({\"topic\": \"IA\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "692661e1-c92a-44cd-92bc-1ece6a17579f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "Explique-me em 1 parágrafo o conceito de {topic}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n"
     ]
    }
   ],
   "source": [
    "print(user_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b103d0f-efc8-49ac-b2e1-e3ee1428342a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['topic'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Você é um assistente e está respondendo perguntas gerais.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\nExplique-me em 1 parágrafo o conceito de {topic}<|eot_id|><|start_header_id|>assistant<|end_header_id|>'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0173aa-8f6d-4b72-abeb-4556ad65ee73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "213a7976-2aa8-4a80-b474-8b418ccb20b5",
   "metadata": {},
   "source": [
    "<h4>Lembre-se que o template e tokens especiais pode mudar. Caso esteja definindo manualmente e não de modo automático usando o tokenizer então você deve sempre confira a descrição do modelo.<br><br>\n",
    "\n",
    "Para avançarmos com o exemplos, é deixado preparado esse template</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1dcfd182-4f27-4fc1-bcbb-42ee2eb9d065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='\\n<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nVocê é um assistente e está respondendo perguntas gerais.\\n<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExplique para mim brevemente o conceito de {topic}, de forma clara e objetiva. Escreva em no máximo 1 parágrafo.\\n<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>\\n')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt = \"Você é um assistente e está respondendo perguntas gerais.\"\n",
    "user_prompt = \"Explique para mim brevemente o conceito de {topic}, de forma clara e objetiva. Escreva em no máximo 1 parágrafo.\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template.format(system_prompt = system_prompt, user_prompt = user_prompt))\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f4c17c6-f65c-4ac0-a4cb-d4d7ae1f030a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='\\n<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nVocê é um assistente e está respondendo perguntas gerais.\\n<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExplique para mim brevemente o conceito de IA, de forma clara e objetiva. Escreva em no máximo 1 parágrafo.\\n<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>\\n')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.invoke({\"topic\": \"IA\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f2f5fe4-288a-49fb-b7b7-696d2736e4e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='\\n<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nVocê é um assistente e está respondendo perguntas gerais.\\n<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExplique para mim brevemente o conceito de IA, de forma clara e objetiva. Escreva em no máximo 1 frase.\\n<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>\\n')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adicionando mais uma variável \n",
    "\n",
    "user_prompt = \"Explique para mim brevemente o conceito de {topic}, de forma clara e objetiva. Escreva em no máximo {tamanho}.\"\n",
    "prompt = PromptTemplate.from_template(template.format(system_prompt=system_prompt, user_prompt=user_prompt))\n",
    "prompt.invoke({\"topic\": \"IA\", \"tamanho\": \"1 frase\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14294c65-526e-48ea-9f6d-2d22f28b0903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "252da4e3-9313-431d-a617-4afab53e0d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['tamanho', 'topic'] input_types={} partial_variables={} template='\\n<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nVocê é um assistente e está respondendo perguntas gerais.\\n<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExplique para mim brevemente o conceito de {topic}, de forma clara e objetiva. Escreva em no máximo {tamanho}.\\n<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>\\n'\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1874810-d5d4-4515-9142-477b34bf9ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
